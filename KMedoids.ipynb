{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KMedoids.ipynb","provenance":[{"file_id":"1QN63DmiSQD0cOzJn3LzFUpxBfHHg0A8n","timestamp":1613574567191}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mih7aOGdP7jn","executionInfo":{"status":"ok","timestamp":1615704350643,"user_tz":-360,"elapsed":23175,"user":{"displayName":"Meheraj Hossain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEUOUPMuw_GVN7Yx2yjJ6aDNBimf5OgKegmz2TCw=s64","userId":"08278156670649380800"}},"outputId":"81e525b3-bd03-4446-a0c1-8cd6cb97cdfb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gS_2jcWeBpY_"},"source":["## Importing necessary libraries\n"]},{"cell_type":"code","metadata":{"id":"npLFrYs0TGIn"},"source":["import numpy as np\n","import pandas as pd\n","import tracemalloc\n","from copy import deepcopy\n","import time\n","import matplotlib.pyplot as plt\n","from scipy.spatial.distance import cdist\n","from scipy.stats import mode\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WlcBnbdHx-O_"},"source":["## Algorithm Directory path"]},{"cell_type":"code","metadata":{"id":"aY3Qdl24yMOT"},"source":["# All the results are stored in this directory\n","directoryPath = '/content/drive/MyDrive/Colab Notebooks/Data Mining Assignments/Clustering/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l2YHazDtBzQS"},"source":["## K Medoids Clustering"]},{"cell_type":"code","metadata":{"id":"du2DajFNn2C3"},"source":["class KMedoidsClustering:\n","\n","  def __init__(self, X, Y, K, dataType=\"numerical\", attributeTypes = [], ranks = {}, numberOfIterations = 5, randomState = 24, symmetricity = {}):\n","    self.X = X\n","    self.Y = Y\n","    self.K = K\n","    self.representativeObjects = {}\n","    self.representativeObjectsIdx = np.array([])\n","    self.clusterLabels = None\n","    self.dataType = dataType\n","    self.attributeInfo = self.get_attribute_info(deepcopy(attributeTypes), ranks, symmetricity)\n","    self.randomState = randomState\n","    self.numberOfIterations = numberOfIterations\n","    self.absoluteErrorCriterion = 0.0\n","    self.withinClusterVariance = 0.0\n","    self.bCubedPrecision = 0.0\n","    self.bCubedRecall = 0.0\n","    self.silhouetteCoefficient = 0.0 \n","    \n","    if self.dataType == \"mixed\":\n","      assert len(attributeTypes) == self.X.shape[1], \"If dataset type is mixed, then attributeType for each attribute needs to be passed.\"\n","\n","  def get_withinClusterVariance(self):\n","    return self.withinClusterVariance\n","\n","  def get_BCubedPrecision(self):\n","    return self.bCubedPrecision\n","\n","  def get_BCubedRecall(self):\n","    return self.bCubedRecall\n","\n","  def get_silhouetteCoefficient(self):\n","    return self.silhouetteCoefficient\n","\n","  def train(self):\n","    minn = np.inf\n","    XNumerical, XNominal, XOrdinal = self.preprocess_X()\n","    for i in range(self.numberOfIterations):\n","      # print(\"Iteration no {}\".format(i))\n","      # print(\"____________________________________________\\n\")\n","      representativeObjectsIdx, absoluteErrorCriterion, clusterLabels, withinClusterVariance = self.trainOnce(XNumerical, XNominal, XOrdinal, i)\n","      # print(\"\\nIteration : {} and absoluteErrorCriterion : {}\\n\".format(i, absoluteErrorCriterion))\n","\n","      if absoluteErrorCriterion < minn:\n","        minn = absoluteErrorCriterion\n","        self.representativeObjectsIdx = representativeObjectsIdx\n","        self.clusterLabels = clusterLabels\n","        self.withinClusterVariance = withinClusterVariance\n","        self.absoluteErrorCriterion = minn\n","    \n","    self.silhouetteCoefficient = self.calculate_silhouette_coefficient()\n","    # print(\"\\n withinClusterVariance : {}\\n\".format(self.withinClusterVariance))\n","    # print(\"\\n silhouetteCoefficient : {}\\n\".format(self.silhouetteCoefficient))\n","    if len(self.Y):\n","      self.bCubedPrecision = self.calculate_bcubed_precision()\n","      self.bCubedRecall = self.calculate_bcubed_recall()\n","      # print(\"\\n bCubedPrecision : {}\\n\".format(self.bCubedPrecision))\n","      # print(\"\\n bCubedRecall : {}\\n\".format(self.bCubedRecall))\n","    \n","  def calculate_distances_from_representativeObjects(self, XNumerical, XOrdinal, XNominal, representativeObjectsIdx):\n","    ## eliminating square root from the euclidean distance calculation\n","    ## that means pairwise squared distances from cluster centers and the samples \n","    pairwiseDistancesNumerical = 0 if len(XNumerical) == 0 else cdist(XNumerical, XNumerical[representativeObjectsIdx, :], metric='euclidean') ** 2\n","    pairwiseDistancesOrdinal = 0 if len(XOrdinal) == 0 else cdist(XOrdinal, XOrdinal[representativeObjectsIdx, :], metric='euclidean') ** 2  \n","    # hamming distance for nominal attributes\n","    pairwiseDistancesNominal = 0 if len(XNominal) == 0 else self.calculate_hamming_distance(XNominal, XNominal[representativeObjectsIdx, :]) \n","\n","    pairwiseDistances = pairwiseDistancesNumerical + pairwiseDistancesNominal + pairwiseDistancesOrdinal\n","    return np.sqrt(pairwiseDistances)\n","\n","  def preprocess_X(self):\n","    XNumerical, XNominal, XOrdinal = np.array([]), np.array([]), np.array([])\n","    if self.dataType == 'numerical':\n","      XNumerical = self.X.astype(float)\n","      XNumerical = self.normalize_numerical_values(XNumerical)\n","    \n","    elif self.dataType == 'nominal':\n","      XNominal = self.X\n","    \n","    elif self.dataType == 'ordinal':\n","      XOrdinal = self.X\n","      XOrdinal = self.format_ordinal_values(XOrdinal)\n","\n","    elif self.dataType == 'mixed':\n","      XNumerical, XNominal, XOrdinal, _, _ = self.seperate_mixed_data()\n","      XNumerical = self.normalize_numerical_values(XNumerical) if len(XNumerical) else np.array([])\n","      XOrdinal = self.format_ordinal_values(XOrdinal) if len(XOrdinal) else np.array([])\n","    \n","    return XNumerical, XNominal, XOrdinal\n","\n","  def trainOnce(self, XNumerical, XNominal, XOrdinal, iterationNum = 0):\n","\n","    np.random.seed(self.randomState + iterationNum)\n","    allObjectsIdx = np.arange(self.X.shape[0])\n","    representativeObjectsIdx = np.random.choice(self.X.shape[0], self.K, replace=False)\n","    # print(\"representativeObjectsIdx : {}\".format(representativeObjectsIdx))\n","\n","    mask = np.ones(self.X.shape[0]).astype(bool)\n","    mask[representativeObjectsIdx] = False\n","    nonRepresentativeObjectsIdx = allObjectsIdx[mask]\n","\n","    pairwiseDistances = self.calculate_distances_from_representativeObjects(XNumerical, XOrdinal, XNominal, representativeObjectsIdx)\n","    absoluteErrorCriterion = np.sum(np.min(pairwiseDistances, axis = 1))\n","    withinClusterVariance = np.sum(np.min(pairwiseDistances**2, axis = 1))\n","    # print(\"absoluteErrorCriterion : {}\".format(absoluteErrorCriterion))\n","    clusterLabels = np.argmin(pairwiseDistances, axis = 1)\n","    # plot_cluster(XNumerical, self.K, representativeObjectsIdx, clusterLabels)\n","\n","    while True: \n","      anyCenterUpdated = False \n","      for k in range(self.K):\n","        np.random.shuffle(nonRepresentativeObjectsIdx)\n","        tempRepresentativeObjectsIdx = deepcopy(representativeObjectsIdx)\n","        for i in range(len(nonRepresentativeObjectsIdx)):\n","          tempRepresentativeObjectsIdx[k] = nonRepresentativeObjectsIdx[i]\n","          tempPairwiseDistances = self.calculate_distances_from_representativeObjects(XNumerical, XOrdinal, XNominal, tempRepresentativeObjectsIdx)\n","          tempAbsoluteErrorCriterion = np.sum(np.min(tempPairwiseDistances, axis = 1))\n","\n","          if tempAbsoluteErrorCriterion < absoluteErrorCriterion:\n","            absoluteErrorCriterion = tempAbsoluteErrorCriterion\n","            withinClusterVariance = np.sum(np.min(tempPairwiseDistances**2, axis = 1))\n","            nonRepresentativeObjectsIdx[i], representativeObjectsIdx[k] = representativeObjectsIdx[k], nonRepresentativeObjectsIdx[i]\n","            clusterLabels = np.argmin(tempPairwiseDistances, axis = 1)\n","            anyCenterUpdated = True\n","            # plot_cluster(XNumerical, self.K, representativeObjectsIdx, clusterLabels)\n","            # print(\"representativeObjectsIdx : {}\".format(representativeObjectsIdx))\n","            # print(\"absoluteErrorCriterion : {}\".format(absoluteErrorCriterion))\n","            break\n","\n","      if not anyCenterUpdated:\n","        break\n","\n","    return representativeObjectsIdx, absoluteErrorCriterion, clusterLabels, withinClusterVariance\n","\n","  def calculate_hamming_distance(self, X, Y):\n","    pairwiseHammingDistance = []\n","    for x in X:\n","      distance = (x != Y).astype(int).sum(axis = 1) \n","      pairwiseHammingDistance.append(distance)\n","\n","    return np.array(pairwiseHammingDistance)\n","\n","  def normalize_numerical_values(self, XNumerical):\n","    mx, mn = np.array([]), np.array([])\n","    for attr in self.attributeInfo:\n","      if attr['type'] == 'numerical':\n","        mx = np.append(mx, attr['max'])\n","        mn = np.append(mn, attr['min'])\n","    \n","    XNumerical = (XNumerical - mn) / (mx - mn)\n","    return XNumerical\n","\n","  def format_ordinal_values(self, XOrdinal):\n","    ranks = []\n","    for attr in self.attributeInfo:\n","      if attr['type'] == 'ordinal':\n","        ranks.append(attr['rank'])\n","\n","    for j in range(XOrdinal.shape[1]):\n","      rank = ranks[j]\n","      if len(rank):\n","        for i in range(XOrdinal.shape[0]):\n","          XOrdinal[i, j] = rank[XOrdinal[i, j]]\n","\n","    XOrdinal = XOrdinal.astype(float)\n","\n","    # scaling each attribute in the range [0, 1]\n","    for j in range(XOrdinal.shape[1]):\n","      XOrdinal[:, j] = (XOrdinal[:, j] - 1)/(np.max(XOrdinal[:, j]) - 1)\n","    \n","    return XOrdinal\n","\n","  def get_attribute_info(self, attributeTypes, ranks, symmetricity):\n","    attributeInfo = []\n","    \n","    for i in range(self.X.shape[1]):\n","      column = self.X[:, i]\n","      distinctValues = np.unique(column)\n","      if len(attributeTypes) <= i:\n","        attributeTypes.append(self.dataType)\n","\n","      attributeInfo.append({\n","          'idx' : i,\n","          'type' : attributeTypes[i],\n","          'distinctValues' : distinctValues if attributeTypes[i] != 'numerical' else None,\n","          'max' : np.amax(column.astype(float)) if attributeTypes[i] == 'numerical' else None,\n","          'min' : np.amin(column.astype(float)) if attributeTypes[i] == 'numerical' else None,\n","          'rank' : ranks[i] if i in ranks else {},\n","          'symmetricity' : symmetricity[i] if i in symmetricity else None\n","      })\n","\n","    return np.array(attributeInfo)\n","\n","  def seperate_mixed_data(self):\n","    attributeTypes = np.array([])\n","    symmetricIdxs, asymmetricIdxs = np.array([]), np.array([])\n","    for attr in self.attributeInfo:\n","      attributeTypes = np.append(attributeTypes, attr['type'])\n","      if attr['type'] == 'binary' and attr['symmetricity'] == 'symmetric':\n","        symmetricIdxs = np.append(symmetricIdxs, attr['idx'])\n","      elif attr['type'] == 'binary' and attr['symmetricity'] == 'asymmetric':\n","        asymmetricIdxs = np.append(asymmetricIdxs, attr['idx'])\n","    \n","    XNumerical = self.X[:, attributeTypes == 'numerical']\n","    XNominal = self.X[:, attributeTypes == 'nominal']\n","    XOrdinal = self.X[:, attributeTypes == 'ordinal']\n","    XBinarySymmetric = self.X[:, symmetricIdxs] if len(symmetricIdxs) else np.array([])\n","    XBinaryAsymmetric = self.X[:, asymmetricIdxs] if len(asymmetricIdxs) else np.array([])\n","\n","    XNumerical = XNumerical.astype(float)\n","    # XBinarySymmetric = XBinarySymmetric.astype(int)\n","    # XBinaryAsymmetric = XBinaryAsymmetric.astype(int)\n","\n","    return XNumerical, XNominal, XOrdinal, XBinarySymmetric, XBinaryAsymmetric\n","\n","  def calculate_pairwise_distances(self, XNumerical, XOrdinal, XNominal, ObjectsIdx1, objectsIdx2):\n","    ## eliminating square root from the euclidean distance calculation\n","    ## that means pairwise squared distances from cluster centers and the samples \n","    pairwiseDistancesNumerical = 0 if len(XNumerical) == 0 else cdist(XNumerical[ObjectsIdx1, :], XNumerical[objectsIdx2, :], metric='euclidean') ** 2\n","    pairwiseDistancesOrdinal = 0 if len(XOrdinal) == 0 else cdist(XOrdinal[ObjectsIdx1, :], XOrdinal[objectsIdx2, :], metric='euclidean') ** 2  \n","    # hamming distance for nominal attributes\n","    pairwiseDistancesNominal = 0 if len(XNominal) == 0 else self.calculate_hamming_distance(XNominal[ObjectsIdx1, :], XNominal[objectsIdx2, :]) \n","\n","    pairwiseDistances = pairwiseDistancesNumerical + pairwiseDistancesNominal + pairwiseDistancesOrdinal\n","    return np.sqrt(pairwiseDistances)\n","\n","  def calculate_silhouette_coefficient(self):\n","    s = np.array([])\n","    XNumerical, XNominal, XOrdinal = self.preprocess_X()\n","    for i in range(self.X.shape[0]):\n","      minn = np.inf\n","      for k in range(self.K):\n","        clusterObjectsIdx = (self.clusterLabels == k)\n","        pairwiseDistances = self.calculate_pairwise_distances(XNumerical, XOrdinal, XNominal, np.array([i]), clusterObjectsIdx)\n","        if self.clusterLabels[i] == k:\n","          avgDistance = 0.0 if clusterObjectsIdx.sum() == 1 else pairwiseDistances.sum() / (clusterObjectsIdx.sum()-1)\n","          a = avgDistance\n","        else:\n","          avgDistance = pairwiseDistances.sum() / clusterObjectsIdx.sum()\n","          minn = min(minn, avgDistance)\n","      b = minn\n","      s = np.append(s, (b-a) / max(a,b) )\n","\n","    return np.mean(s)  \n","\n","  def calculate_bcubed_precision(self):\n","    bCubedPrecision = 0.0\n","    for i in range(self.X.shape[0]):\n","      clusterObjectsIdx = (self.clusterLabels == self.clusterLabels[i])\n","      correctNess = (self.Y[clusterObjectsIdx] == self.Y[i]).sum()\n","      avgCorrectNess = 0 if clusterObjectsIdx.sum() == 1 else (correctNess-1)/ (clusterObjectsIdx.sum()-1)\n","      bCubedPrecision += avgCorrectNess\n","\n","    return bCubedPrecision/ self.X.shape[0]\n","\n","  def calculate_bcubed_recall(self):\n","    bCubedRecall = 0.0\n","    for i in range(self.X.shape[0]):\n","      sameClassObjectsIdx = (self.Y == self.Y[i])\n","      correctNess = (self.clusterLabels[sameClassObjectsIdx] == self.clusterLabels[i]).sum()\n","      avgCorrectNess = 0 if sameClassObjectsIdx.sum() == 1 else (correctNess-1)/ (sameClassObjectsIdx.sum()-1)\n","      bCubedRecall += avgCorrectNess\n","      \n","    return bCubedRecall/ self.X.shape[0]\n","\n","  def predict_one(self, x):\n","    return\n","\n","  def predict(self, XTest):\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUnlcH-Lyxf-"},"source":["def plot_cluster(X, K, representativeObjectsIdx, clusterLabels):\n","    color = [\"red\",\"green\", \"blue\", \"yellow\", \"black\"]\n","    for k in range(K):\n","        plt.scatter(X[clusterLabels == k, 0], X[clusterLabels == k, 1], color=color[k])\n","    \n","    plt.scatter(X[representativeObjectsIdx, 0] , X[representativeObjectsIdx, 1], color=\"black\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Umua9Ot5n366"},"source":["##Running on Sample datasets\n"]},{"cell_type":"code","metadata":{"id":"Y_QxeVwGnt0H"},"source":["# dName = 'sampleDataset-1.csv'\n","# filePath = '{}Datasets/{}'.format(directoryPath, dName)\n","# df = pd.read_csv(filePath, sep=\",\", header=None)\n","\n","# X = df.to_numpy()\n","# Y = np.array([])\n","# print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","\n","# kMedoidsClustering = KMedoidsClustering(X, Y, K = 4, dataType=\"numerical\")\n","# kMedoidsClustering.train()\n","# plot_cluster(kMedoidsClustering.normalize_numerical_values(X), 4, kMedoidsClustering.representativeObjectsIdx, kMedoidsClustering.clusterLabels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZA9i0SI3r0ow"},"source":["# dName = 'sampleDataset-2.csv'\n","# filePath = '{}Datasets/{}'.format(directoryPath, dName)\n","# df = pd.read_csv(filePath, sep=\",\", header=None)\n","\n","# X = df.to_numpy()\n","# Y = np.array([])\n","# print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","\n","# kMedoidsClustering = KMedoidsClustering(X, Y, K = 4, dataType=\"numerical\")\n","# kMedoidsClustering.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4e1gL1FMw2O4"},"source":["# from sklearn.datasets import load_iris\n","# X, Y = load_iris(return_X_y= True)\n","# Y = np.squeeze(Y)\n","# # print(Y)\n","# # print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","\n","# kMedoidsClustering = KMedoidsClustering(X, Y, K = 3, dataType=\"numerical\")\n","# kMedoidsClustering.train()\n","# # print(kMedoidsClustering.absoluteErrorCriterion)\n","# # print(kMedoidsClustering.clusterLabels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6evGljMoR1Zl"},"source":["# "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JAJAAk4V2Lho"},"source":[""],"execution_count":null,"outputs":[]}]}