{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KMeans.ipynb","provenance":[{"file_id":"1QN63DmiSQD0cOzJn3LzFUpxBfHHg0A8n","timestamp":1613574567191}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mih7aOGdP7jn","executionInfo":{"status":"ok","timestamp":1615719655298,"user_tz":-360,"elapsed":2049,"user":{"displayName":"Meheraj Hossain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEUOUPMuw_GVN7Yx2yjJ6aDNBimf5OgKegmz2TCw=s64","userId":"08278156670649380800"}},"outputId":"be749d44-c1cb-4bf4-f166-dba8719a4733"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gS_2jcWeBpY_"},"source":["## Importing necessary libraries\n"]},{"cell_type":"code","metadata":{"id":"npLFrYs0TGIn"},"source":["import numpy as np\n","import pandas as pd\n","import tracemalloc\n","from copy import deepcopy\n","import time\n","import matplotlib.pyplot as plt\n","from scipy.spatial.distance import cdist\n","from scipy.stats import mode\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WlcBnbdHx-O_"},"source":["## Algorithm Directory path"]},{"cell_type":"code","metadata":{"id":"aY3Qdl24yMOT"},"source":["# All the results are stored in this directory\n","directoryPath = '/content/drive/MyDrive/Colab Notebooks/Data Mining Assignments/Clustering/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l2YHazDtBzQS"},"source":["## K Means Clustering"]},{"cell_type":"code","metadata":{"id":"du2DajFNn2C3"},"source":["class KMeansClustering:\n","\n","  def __init__(self, X, Y, K, dataType=\"numerical\", attributeTypes = [], ranks = {}, numberOfIterations = 5, randomState = 24, symmetricity = {}):\n","    self.X = X\n","    self.Y = Y\n","    self.K = K\n","    self.clusterCenters = {}\n","    self.clusterLabels = None\n","    self.dataType = dataType\n","    self.attributeInfo = self.get_attribute_info(deepcopy(attributeTypes), ranks, symmetricity)\n","    self.randomState = randomState\n","    self.numberOfIterations = numberOfIterations\n","    self.withinClusterVariance = 0.0\n","    self.bCubedPrecision = 0.0\n","    self.bCubedRecall = 0.0\n","    self.silhouetteCoefficient = 0.0 \n","    \n","    if self.dataType == \"mixed\":\n","      assert len(attributeTypes) == self.X.shape[1], \"If dataset type is mixed, then attributeType for each attribute needs to be passed.\"\n","\n","  def get_withinClusterVariance(self):\n","    return self.withinClusterVariance\n","\n","  def get_BCubedPrecision(self):\n","    return self.bCubedPrecision\n","\n","  def get_BCubedRecall(self):\n","    return self.bCubedRecall\n","\n","  def get_silhouetteCoefficient(self):\n","    return self.silhouetteCoefficient\n","\n","  def train(self):\n","    minn = np.inf\n","    XNumerical, XNominal, XOrdinal = self.preprocess_X()\n","    for i in range(self.numberOfIterations):\n","      clusterCenters, withinClusterVariance, clusterLabels = self.trainOnce(XNumerical, XNominal, XOrdinal, i)\n","      # print(\"\\nIteration : {} and withinClusterVariance : {}\\n\".format(i, withinClusterVariance))\n","\n","      if withinClusterVariance < minn:\n","        minn = withinClusterVariance\n","        self.clusterCenters = clusterCenters\n","        self.clusterLabels = clusterLabels\n","        self.withinClusterVariance = minn\n","\n","    self.silhouetteCoefficient = self.calculate_silhouette_coefficient()\n","    # print(\"\\n withinClusterVariance : {}\\n\".format(self.withinClusterVariance))\n","    # print(\"\\n silhouetteCoefficient : {}\\n\".format(self.silhouetteCoefficient))\n","    if len(self.Y):\n","      self.bCubedPrecision = self.calculate_bcubed_precision()\n","      self.bCubedRecall = self.calculate_bcubed_recall()\n","      # print(\"\\n bCubedPrecision : {}\\n\".format(self.bCubedPrecision))\n","      # print(\"\\n bCubedRecall : {}\\n\".format(self.bCubedRecall))\n","\n","  def preprocess_X(self):\n","    XNumerical, XNominal, XOrdinal = np.array([]), np.array([]), np.array([])\n","    if self.dataType == 'numerical':\n","      XNumerical = self.X.astype(float)\n","      XNumerical = self.normalize_numerical_values(XNumerical)\n","      # print(XNumerical)\n","    \n","    elif self.dataType == 'nominal':\n","      XNominal = self.X\n","    \n","    elif self.dataType == 'ordinal':\n","      XOrdinal = self.X\n","      XOrdinal = self.format_ordinal_values(XOrdinal)\n","      # print(XOrdinal)\n","\n","    elif self.dataType == 'mixed':\n","      XNumerical, XNominal, XOrdinal, _, _ = self.seperate_mixed_data()\n","      XNumerical = self.normalize_numerical_values(XNumerical) if len(XNumerical) else np.array([])\n","      XOrdinal = self.format_ordinal_values(XOrdinal) if len(XOrdinal) else np.array([])\n","    \n","    return XNumerical, XNominal, XOrdinal\n","\n","  def trainOnce(self, XNumerical, XNominal, XOrdinal, iterationNum = 0, eps = 1e-6):\n","    withinClusterVariance = 0.0\n","    np.random.seed(self.randomState + iterationNum)\n","    clusterCentersIdx = np.random.choice(self.X.shape[0], self.K, replace=False)\n","    clusterCentersNumerical = XNumerical[clusterCentersIdx, :] if len(XNumerical) else np.array([])\n","    clusterCentersNominal = XNominal[clusterCentersIdx, :] if len(XNominal) else np.array([])\n","    clusterCentersOrdinal = XOrdinal[clusterCentersIdx, :] if len(XOrdinal) else np.array([])\n","\n","    while True:\n","      ## eliminating square root from the euclidean distance calculation\n","      ## that means pairwise squared distances from cluster centers and the samples \n","      pairwiseDistancesNumerical = 0 if len(XNumerical) == 0 else cdist(XNumerical, clusterCentersNumerical, metric='euclidean') ** 2\n","      pairwiseDistancesOrdinal = 0 if len(XOrdinal) == 0 else cdist(XOrdinal, clusterCentersOrdinal, metric='euclidean') ** 2  \n","      # hamming distance for nominal attributes\n","      pairwiseDistancesNominal = 0 if len(XNominal) == 0 else self.calculate_hamming_distance(XNominal, clusterCentersNominal) \n","\n","      pairwiseDistances = pairwiseDistancesNumerical + pairwiseDistancesNominal + pairwiseDistancesOrdinal\n","      # print(\"withinClusterVariance for iteration {} : {}\".format(iterationNum, np.sum(np.min(pairwiseDistances, axis = 1))))\n","      clusterLabels = np.argmin(pairwiseDistances, axis = 1)\n","\n","      anyCenterUpdated = False \n","\n","      for k in range(self.K):\n","        centerDifference = 0.0\n","        clusterObjectsIdx = (clusterLabels == k)\n","        newClusterCenterNumerical, newClusterCenterOrdinal, newClusterCenterNominal = np.array([]), np.array([]), np.array([])\n","        if len(XNumerical):\n","          singleClusterNumerical = XNumerical[clusterObjectsIdx, :]\n","          newClusterCenterNumerical = np.mean(singleClusterNumerical, axis = 0)\n","          centerDifference += np.linalg.norm(clusterCentersNumerical[k] - newClusterCenterNumerical)\n","        if len(XOrdinal):\n","          singleClusterOrdinal = XOrdinal[clusterObjectsIdx, :]\n","          newClusterCenterOrdinal = np.mean(singleClusterOrdinal, axis = 0)\n","          centerDifference += np.linalg.norm(clusterCentersOrdinal[k] - newClusterCenterOrdinal)\n","        if len(XNominal):\n","          singleClusterNominal = XNominal[clusterObjectsIdx, :]\n","          newClusterCenterNominal, _ = mode(singleClusterNominal, axis = 0)\n","          newClusterCenterNominal = np.squeeze(newClusterCenterNominal)\n","          centerDifference += (clusterCentersNominal[k] != newClusterCenterNominal).sum()\n","\n","        # print(newClusterCenterNumerical)\n","        # print(newClusterCenterNominal)\n","\n","        if centerDifference > eps:\n","          anyCenterUpdated = True\n","          if len(clusterCentersNumerical):\n","            clusterCentersNumerical[k] = newClusterCenterNumerical\n","          if len(clusterCentersOrdinal):\n","            clusterCentersOrdinal[k] = newClusterCenterOrdinal\n","          if len(clusterCentersNominal):\n","            clusterCentersNominal[k] = newClusterCenterNominal\n","\n","      if not anyCenterUpdated:\n","        withinClusterVariance = np.sum(np.min(pairwiseDistances, axis = 1))\n","        break\n","\n","    clusterCenters = {\n","        'numerical' : clusterCentersNumerical,\n","        'nominal' : clusterCentersNominal,\n","        'ordinal' : clusterCentersOrdinal\n","    }\n","    return clusterCenters, withinClusterVariance, clusterLabels\n","\n","  def calculate_hamming_distance(self, X, Y):\n","    pairwiseHammingDistance = []\n","    for x in X:\n","      distance = (x != Y).astype(int).sum(axis = 1) \n","      pairwiseHammingDistance.append(distance)\n","\n","    return np.array(pairwiseHammingDistance)\n","      \n","  def normalize_numerical_values(self, XNumerical):\n","    mx, mn = np.array([]), np.array([])\n","    for attr in self.attributeInfo:\n","      if attr['type'] == 'numerical':\n","        mx = np.append(mx, attr['max'])\n","        mn = np.append(mn, attr['min'])\n","\n","    # print(mn, mn)\n","\n","    XNumerical = (XNumerical - mn) / (mx - mn)\n","    return XNumerical\n","\n","  def format_ordinal_values(self, XOrdinal):\n","    ranks = []\n","    for attr in self.attributeInfo:\n","      if attr['type'] == 'ordinal':\n","        ranks.append(attr['rank'])\n","\n","    for j in range(XOrdinal.shape[1]):\n","      rank = ranks[j]\n","      if len(rank):\n","        for i in range(XOrdinal.shape[0]):\n","          XOrdinal[i, j] = rank[XOrdinal[i, j]]\n","\n","    XOrdinal = XOrdinal.astype(float)\n","\n","    # scaling each attribute in the range [0, 1]\n","    for j in range(XOrdinal.shape[1]):\n","      XOrdinal[:, j] = (XOrdinal[:, j] - 1)/(np.max(XOrdinal[:, j]) - 1)\n","    \n","    return XOrdinal\n","\n","  def get_attribute_info(self, attributeTypes, ranks, symmetricity):\n","    attributeInfo = []\n","    \n","    for i in range(self.X.shape[1]):\n","      column = self.X[:, i]\n","      distinctValues = np.unique(column)\n","      if len(attributeTypes) <= i:\n","        attributeTypes.append(self.dataType)\n","\n","      attributeInfo.append({\n","          'idx' : i,\n","          'type' : attributeTypes[i],\n","          'distinctValues' : distinctValues if attributeTypes[i] != 'numerical' else None,\n","          'max' : np.amax(column.astype(float)) if attributeTypes[i] == 'numerical' else None,\n","          'min' : np.amin(column.astype(float)) if attributeTypes[i] == 'numerical' else None,\n","          'rank' : ranks[i] if i in ranks else {},\n","          'symmetricity' : symmetricity[i] if i in symmetricity else None\n","      })\n","\n","    return np.array(attributeInfo)\n","\n","  def seperate_mixed_data(self):\n","    attributeTypes = np.array([])\n","    symmetricIdxs, asymmetricIdxs = np.array([]), np.array([])\n","    for attr in self.attributeInfo:\n","      attributeTypes = np.append(attributeTypes, attr['type'])\n","      if attr['type'] == 'binary' and attr['symmetricity'] == 'symmetric':\n","        symmetricIdxs = np.append(symmetricIdxs, attr['idx'])\n","      elif attr['type'] == 'binary' and attr['symmetricity'] == 'asymmetric':\n","        asymmetricIdxs = np.append(asymmetricIdxs, attr['idx'])\n","    \n","    XNumerical = self.X[:, attributeTypes == 'numerical']\n","    XNominal = self.X[:, attributeTypes == 'nominal']\n","    XOrdinal = self.X[:, attributeTypes == 'ordinal']\n","    XBinarySymmetric = self.X[:, symmetricIdxs] if len(symmetricIdxs) else np.array([])\n","    XBinaryAsymmetric = self.X[:, asymmetricIdxs] if len(asymmetricIdxs) else np.array([])\n","\n","    XNumerical = XNumerical.astype(float)\n","    # XBinarySymmetric = XBinarySymmetric.astype(int)\n","    # XBinaryAsymmetric = XBinaryAsymmetric.astype(int)\n","\n","    return XNumerical, XNominal, XOrdinal, XBinarySymmetric, XBinaryAsymmetric\n","\n","  def calculate_pairwise_distances(self, XNumerical, XOrdinal, XNominal, ObjectsIdx1, objectsIdx2):\n","    ## eliminating square root from the euclidean distance calculation\n","    ## that means pairwise squared distances from cluster centers and the samples \n","    pairwiseDistancesNumerical = 0 if len(XNumerical) == 0 else cdist(XNumerical[ObjectsIdx1, :], XNumerical[objectsIdx2, :], metric='euclidean') ** 2\n","    pairwiseDistancesOrdinal = 0 if len(XOrdinal) == 0 else cdist(XOrdinal[ObjectsIdx1, :], XOrdinal[objectsIdx2, :], metric='euclidean') ** 2  \n","    # hamming distance for nominal attributes\n","    pairwiseDistancesNominal = 0 if len(XNominal) == 0 else self.calculate_hamming_distance(XNominal[ObjectsIdx1, :], XNominal[objectsIdx2, :]) \n","\n","    pairwiseDistances = pairwiseDistancesNumerical + pairwiseDistancesNominal + pairwiseDistancesOrdinal\n","    return np.sqrt(pairwiseDistances)\n","\n","  def calculate_silhouette_coefficient(self):\n","    s = np.array([])\n","    XNumerical, XNominal, XOrdinal = self.preprocess_X()\n","    for i in range(self.X.shape[0]):\n","      minn = np.inf\n","      for k in range(self.K):\n","        clusterObjectsIdx = (self.clusterLabels == k)\n","        pairwiseDistances = self.calculate_pairwise_distances( XNumerical, XOrdinal, XNominal, np.array([i]), clusterObjectsIdx)\n","        if self.clusterLabels[i] == k:\n","          avgDistance = 0.0 if clusterObjectsIdx.sum() == 1 else pairwiseDistances.sum() / (clusterObjectsIdx.sum()-1)\n","          a = avgDistance\n","        else:\n","          avgDistance = pairwiseDistances.sum() / clusterObjectsIdx.sum()\n","          minn = min(minn, avgDistance)\n","      b = minn\n","      s = np.append(s, (b-a) / max(a,b) )\n","\n","    return np.mean(s)  \n","\n","  def calculate_bcubed_precision(self):\n","    bCubedPrecision = 0.0\n","    for i in range(self.X.shape[0]):\n","      clusterObjectsIdx = (self.clusterLabels == self.clusterLabels[i])\n","      correctNess = (self.Y[clusterObjectsIdx] == self.Y[i]).sum()\n","      avgCorrectNess = 0 if clusterObjectsIdx.sum() == 1 else (correctNess-1)/ (clusterObjectsIdx.sum()-1)\n","      bCubedPrecision += avgCorrectNess\n","\n","    return bCubedPrecision/ self.X.shape[0]\n","\n","  def calculate_bcubed_recall(self):\n","    bCubedRecall = 0.0\n","    for i in range(self.X.shape[0]):\n","      sameClassObjectsIdx = (self.Y == self.Y[i])\n","      correctNess = (self.clusterLabels[sameClassObjectsIdx] == self.clusterLabels[i]).sum()\n","      avgCorrectNess = 0 if sameClassObjectsIdx.sum() == 1 else (correctNess-1)/ (sameClassObjectsIdx.sum()-1)\n","      bCubedRecall += avgCorrectNess\n","      \n","    return bCubedRecall/ self.X.shape[0]\n","\n","  def predict_one(self, x):\n","    return\n","\n","  def predict(self, XTest):\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2vArtdJidf4"},"source":["def plot_cluster(X, K, clusterCenters, clusterLabels):\n","    color = [\"red\",\"green\", \"blue\", \"yellow\", \"black\"]\n","    for k in range(K):\n","        plt.scatter(X[clusterLabels == k, 0], X[clusterLabels == k, 1], color=color[k])\n","    \n","    plt.scatter(clusterCenters[:, 0] , clusterCenters[:, 1], color=\"black\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Umua9Ot5n366"},"source":["##Running on Sample datasets\n"]},{"cell_type":"code","metadata":{"id":"Y_QxeVwGnt0H"},"source":["# dName = 'sampleDataset-1.csv'\n","# filePath = '{}Datasets/{}'.format(directoryPath, dName)\n","# df = pd.read_csv(filePath, sep=\",\", header=None)\n","\n","# X = df.to_numpy()\n","# Y = np.array([])\n","# print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","\n","# kMeansClustering = KMeansClustering(X, Y, K = 4, dataType=\"numerical\")\n","# kMeansClustering.train()\n","# plot_cluster(kMeansClustering.normalize_numerical_values(X), 4, kMeansClustering.clusterCenters[\"numerical\"], kMeansClustering.clusterLabels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZA9i0SI3r0ow"},"source":["# dName = 'sampleDataset-2.csv'\n","# filePath = '{}Datasets/{}'.format(directoryPath, dName)\n","# df = pd.read_csv(filePath, sep=\",\", header=None)\n","\n","# X = df.to_numpy()\n","# Y = np.array([])\n","# print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","\n","# kMeansClustering = KMeansClustering(X, Y, K = 4, dataType=\"numerical\")\n","# kMeansClustering.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4e1gL1FMw2O4"},"source":["# from sklearn.datasets import load_iris\n","# X, Y = load_iris(return_X_y= True)\n","# Y = np.squeeze(Y)\n","# # print(Y)\n","# # print('instances = {}, features= {} '.format(X.shape[0], X.shape[1]))\n","\n","# kMeansClustering = KMeansClustering(X, Y, K = 3, dataType=\"numerical\")\n","# kMeansClustering.train()\n","# # print(kMeansClustering.withinClusterVariance)\n","# # print(kMeansClustering.clusterLabels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQLVzf8NVpE0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajimnIR70-pP"},"source":[""],"execution_count":null,"outputs":[]}]}